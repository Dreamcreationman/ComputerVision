{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:14:20.659575Z",
     "start_time": "2020-06-04T16:14:20.655969Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:14:21.083030Z",
     "start_time": "2020-06-04T16:14:21.078348Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:57:29.804232Z",
     "start_time": "2020-06-04T16:57:29.795019Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, input_ch, output_ch, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_ch, out_channels=output_ch, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(output_ch)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=output_ch, out_channels=output_ch, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(output_ch)\n",
    "        self.downsample = downsample\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        residual = inputs\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(inputs)\n",
    "        x += residual\n",
    "        output = self.relu(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T17:02:15.948625Z",
     "start_time": "2020-06-04T17:02:15.934501Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.c1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer1 = self.make_layer(block, 16, 3)\n",
    "        self.layer2 = self.make_layer(block, 32, 3, 2)\n",
    "        self.layer3 = self.make_layer(block, 64, 3, 2)\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=8)\n",
    "        self.fc = nn.Linear(64, 10)\n",
    "    \n",
    "    def make_layer(self, block, output_ch, num_blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (self.in_channels != output_ch) or (stride != 1):\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=self.in_channels, out_channels=output_ch, kernel_size=3, stride=stride, padding=1),\n",
    "                nn.BatchNorm2d(output_ch)\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, output_ch, stride, downsample))\n",
    "        self.in_channels = output_ch\n",
    "        for i in range(1, num_blocks):\n",
    "            layers.append(block(output_ch, output_ch))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T17:02:16.314549Z",
     "start_time": "2020-06-04T17:02:16.296669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (c1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (layer1): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avg_pool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(ResBlock).to(device)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T17:02:17.578954Z",
     "start_time": "2020-06-04T17:02:17.574175Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "WEIGHT_DECAY = 0.0001\n",
    "MOMENTUM = 0.9\n",
    "LEARNING_RATE_BASE = 0.1\n",
    "EPOCH = 140\n",
    "\n",
    "learning_rate = LEARNING_RATE_BASE\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=WEIGHT_DECAY,momentum=MOMENTUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T17:02:18.128072Z",
     "start_time": "2020-06-04T17:02:18.124705Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T17:02:19.843233Z",
     "start_time": "2020-06-04T17:02:18.483695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataset_train = datasets.CIFAR10(root=\"./data\", download=True, train=True, transform=transform)\n",
    "dataset_test = datasets.CIFAR10(root=\"./data\", train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T17:02:27.770426Z",
     "start_time": "2020-06-04T17:02:19.845210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "128\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "128\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "128\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "128\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "128\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "128\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 16, 32, 32]) torch.Size([128, 16, 32, 32])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 32, 16, 16]) torch.Size([128, 32, 16, 16])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "torch.Size([128, 64, 8, 8]) torch.Size([128, 64, 8, 8])\n",
      "128\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-6ae3e640ebff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/research/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/research/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_iteration = 0\n",
    "loss_data = []\n",
    "for epoch in range(EPOCH):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        num_iteration += 1\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        ouputs = model(inputs)\n",
    "        loss = criterion(ouputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if num_iteration % 100 == 0:\n",
    "            print(\"{}/140 Epoch----{}k/64k iterations: Loss:{:.6f}\".format(epoch, num_iteration / 1000, loss.item()))\n",
    "            loss_data.append(loss.item())\n",
    "            torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss_data,\n",
    "                    }, \"checkpoint.pt\")\n",
    "        \n",
    "        if num_iteration == 32000 or num_iteration == 48000:\n",
    "            learning_rate = learning_rate / 10\n",
    "            update_lr(optimizer, learning_rate)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        test_inputs = test_inputs.to(device)\n",
    "        test_labels = test_labels.to(device)\n",
    "        \n",
    "        outs = model(test_inputs)\n",
    "        _, predicted = torch.max(outs.data, 1)\n",
    "        total += test_labels.size(0)\n",
    "        correct += (predicted == test_labels).sum().item()\n",
    "        \n",
    "    print(\"Accuracy:{}%\".format(100 * correct / total))\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), \"cifar10_resnet.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
